{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7cd1ab-d352-4f76-9a31-bfabe329fc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/9.7 MB 9.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.9/9.7 MB 24.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.2/9.7 MB 29.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.8/9.7 MB 30.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.8/9.7 MB 36.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.6/9.7 MB 39.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 38.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 34.5 MB/s eta 0:00:00\n",
      "Downloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "   ---------------------------------------- 0.0/481.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 481.7/481.7 kB 31.4 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.4/63.4 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: websocket-client, h11, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-24.3.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.27.1 trio-0.27.0 trio-websocket-0.11.1 websocket-client-1.8.0 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wsdump.exe is installed in 'C:\\Users\\bartaria\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install selenium\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Initialize WebDriver (Make sure you have ChromeDriver installed and in PATH)\n",
    "def initialize_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--window-size=1920x1080\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# Extract branch addresses from a single page\n",
    "def get_branch_addresses(driver, page_url):\n",
    "    print(f\"Scraping page: {page_url}\")\n",
    "    driver.get(page_url)  # Navigate to the page\n",
    "    time.sleep(2)  # Wait for the page to load (adjust if needed)\n",
    "    \n",
    "    # Find all address elements\n",
    "    address_elements = driver.find_elements(By.CSS_SELECTOR, 'span.d-block.text-heading.font-size-sm.text-uppercase')\n",
    "    addresses = []\n",
    "    for element in address_elements:\n",
    "        address = element.text.strip()  # Extract and clean text\n",
    "        print(f\"Found address: {address}\")  # Debugging line\n",
    "        addresses.append({\"Address\": address})\n",
    "    \n",
    "    return addresses\n",
    "\n",
    "# Save all collected addresses to a CSV file\n",
    "def save_to_csv(data, filename=\"deutsche_bank_branches.csv\"):\n",
    "    print(f\"Saving {len(data)} addresses to {filename}...\")\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"Address\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "    print(f\"Data saved successfully to {filename}!\")\n",
    "\n",
    "# Main function to scrape all pages\n",
    "def main():\n",
    "    base_url = \"https://deutsche.banklocationmaps.com/en/branches/deu?page={}&partner=hide\"\n",
    "    total_pages = 39  # Number of pages to scrape\n",
    "    all_addresses = []\n",
    "    \n",
    "    # Initialize Selenium WebDriver\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    try:\n",
    "        for page in range(1, total_pages + 1):\n",
    "            page_url = base_url.format(page)\n",
    "            addresses = get_branch_addresses(driver, page_url)\n",
    "            all_addresses.extend(addresses)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "    finally:\n",
    "        driver.quit()  # Ensure the browser is closed\n",
    "\n",
    "    # Save to CSV\n",
    "    save_to_csv(all_addresses)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c6c30d-527e-4ec1-b534-43d12d2712eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 403 Client Error: Forbidden for url: https://deutsche.banklocationmaps.com/en/branches/deu?page=1&partner=hide\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL\n",
    "URL = \"https://deutsche.banklocationmaps.com/en/branches/deu?page=1&partner=hide\"\n",
    "\n",
    "# Define headers copied from your browser\n",
    "HEADERS = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"DNT\": \"1\",\n",
    "    \"Sec-CH-UA\": '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
    "    \"Sec-CH-UA-Mobile\": \"?0\",\n",
    "    \"Sec-CH-UA-Platform\": '\"macOS\"',\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"none\",\n",
    "    \"Sec-Fetch-User\": \"?1\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "}\n",
    "\n",
    "# Send a GET request\n",
    "try:\n",
    "    response = requests.get(URL, headers=HEADERS, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    print(\"Request successful!\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Page Content (truncated): {response.text[:500]}\")  # Print first 500 characters of the content\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109c880b-0d9e-45f2-856c-c2babf75d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL: https://deutsche.banklocationmaps.com/en/branches/deu?page=1&partner=hide\n",
      "Extracted address: Bohlweg 24 38100 Braunschweig\n",
      "Extracted address: Marienplatz 21 80331 München\n",
      "Extracted address: Berliner Allee 61 40212 Düsseldorf\n",
      "Extracted address: Janusz-Korczak-Straße 3-5 12627 Berlin\n",
      "Extracted address: Promenadeplatz 15 80333 München\n",
      "Extracted address: Roßmarkt 18 60311 Frankfurt am Main\n",
      "Extracted address: Stuttgarter Straße 81 70469 Stuttgart\n",
      "Extracted address: Koblenzer Straße 7 57072 Siegen\n",
      "Extracted address: Schweizer Straße 28a/30 60594 Frankfurt am Main\n",
      "Extracted address: Otto-Suhr-Allee 6 10585 Berlin\n",
      "Extracted address: Schönhauser Allee 120 10437 Berlin\n",
      "Extracted address: Taunusanlage 12 60325 Frankfurt am Main\n",
      "Extracted address: Leipziger Straße 17 60487 Frankfurt am Main\n",
      "Extracted address: Schloßstraße 114 12163 Berlin\n",
      "Extracted address: Leopoldstraße 53 80802 München\n",
      "Extracted address: Rotteckring 3 79098 Freiburg\n",
      "Extracted address: Bredeneyer Straße 156-158 45133 Essen\n",
      "Extracted address: Luisenplatz 7 64283 Darmstadt\n",
      "Extracted address: Königsteiner Straße 16 65929 Frankfurt am Main\n",
      "Extracted address: Unter den Linden 13/15 10117 Berlin\n",
      "Found 20 addresses on this page.\n",
      "Scraping URL: https://deutsche.banklocationmaps.com/en/branches/deu?page=2&partner=hide\n",
      "Error waiting for page content: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=131.0.6778.204)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7D6B3FB05+28789]\n",
      "\t(No symbol) [0x00007FF7D6AA86E0]\n",
      "\t(No symbol) [0x00007FF7D694592A]\n",
      "\t(No symbol) [0x00007FF7D691F505]\n",
      "\t(No symbol) [0x00007FF7D69C6477]\n",
      "\t(No symbol) [0x00007FF7D69DEF42]\n",
      "\t(No symbol) [0x00007FF7D69BF1E3]\n",
      "\t(No symbol) [0x00007FF7D698A938]\n",
      "\t(No symbol) [0x00007FF7D698BAA1]\n",
      "\tGetHandleVerifier [0x00007FF7D6E7933D+3410093]\n",
      "\tGetHandleVerifier [0x00007FF7D6E8E7DD+3497293]\n",
      "\tGetHandleVerifier [0x00007FF7D6E82A73+3448803]\n",
      "\tGetHandleVerifier [0x00007FF7D6C07BBB+848171]\n",
      "\t(No symbol) [0x00007FF7D6AB3C3F]\n",
      "\t(No symbol) [0x00007FF7D6AAF6E4]\n",
      "\t(No symbol) [0x00007FF7D6AAF87D]\n",
      "\t(No symbol) [0x00007FF7D6A9ED49]\n",
      "\tBaseThreadInitThunk [0x00007FFB3DF77AC4+20]\n",
      "\tRtlUserThreadStart [0x00007FFB4025A8C1+33]\n",
      "\n",
      "Scraping URL: https://deutsche.banklocationmaps.com/en/branches/deu?page=3&partner=hide\n",
      "An error occurred: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=131.0.6778.204)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7D6B3FB05+28789]\n",
      "\t(No symbol) [0x00007FF7D6AA86E0]\n",
      "\t(No symbol) [0x00007FF7D694592A]\n",
      "\t(No symbol) [0x00007FF7D691F505]\n",
      "\t(No symbol) [0x00007FF7D69C6477]\n",
      "\t(No symbol) [0x00007FF7D69DEF42]\n",
      "\t(No symbol) [0x00007FF7D69BF1E3]\n",
      "\t(No symbol) [0x00007FF7D698A938]\n",
      "\t(No symbol) [0x00007FF7D698BAA1]\n",
      "\tGetHandleVerifier [0x00007FF7D6E7933D+3410093]\n",
      "\tGetHandleVerifier [0x00007FF7D6E8E7DD+3497293]\n",
      "\tGetHandleVerifier [0x00007FF7D6E82A73+3448803]\n",
      "\tGetHandleVerifier [0x00007FF7D6C07BBB+848171]\n",
      "\t(No symbol) [0x00007FF7D6AB3C3F]\n",
      "\t(No symbol) [0x00007FF7D6AAF6E4]\n",
      "\t(No symbol) [0x00007FF7D6AAF87D]\n",
      "\t(No symbol) [0x00007FF7D6A9ED49]\n",
      "\tBaseThreadInitThunk [0x00007FFB3DF77AC4+20]\n",
      "\tRtlUserThreadStart [0x00007FFB4025A8C1+33]\n",
      "\n",
      "Saving 20 addresses to deutsche_bank_branches.csv...\n",
      "Data saved successfully to deutsche_bank_branches.csv!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "\n",
    "# Initialize WebDriver\n",
    "def initialize_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # Comment out the following line for debugging purposes\n",
    "    # options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# Extract branch addresses from a single page\n",
    "def scrape_page(driver, url):\n",
    "    print(f\"Scraping URL: {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Wait for the address elements to load\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.media-body.pl-3 span.d-block.text-heading.font-size-sm.text-uppercase'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error waiting for page content: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Locate and extract branch addresses\n",
    "    branch_elements = driver.find_elements(By.CSS_SELECTOR, 'div.media-body.pl-3 span.d-block.text-heading.font-size-sm.text-uppercase')\n",
    "    addresses = []\n",
    "    for branch in branch_elements:\n",
    "        # Extract full address and handle <br> tags\n",
    "        address = branch.get_attribute(\"innerHTML\").replace(\"<br>\", \" \").strip()\n",
    "        print(f\"Extracted address: {address}\")\n",
    "        addresses.append(address)\n",
    "\n",
    "    print(f\"Found {len(addresses)} addresses on this page.\")\n",
    "    return addresses\n",
    "\n",
    "# Save extracted addresses to a CSV file\n",
    "def save_to_csv(data, filename=\"deutsche_bank_branches.csv\"):\n",
    "    print(f\"Saving {len(data)} addresses to {filename}...\")\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Address\"])  # Header row\n",
    "        for address in data:\n",
    "            writer.writerow([address])\n",
    "    print(f\"Data saved successfully to {filename}!\")\n",
    "\n",
    "# Main function to scrape all pages\n",
    "def main():\n",
    "    base_url = \"https://deutsche.banklocationmaps.com/en/branches/deu?page={}&partner=hide\"\n",
    "    total_pages = 39  # Number of pages to scrape\n",
    "    all_addresses = []\n",
    "\n",
    "    driver = initialize_driver()\n",
    "    try:\n",
    "        for page in range(1, total_pages + 1):\n",
    "            url = base_url.format(page)\n",
    "            addresses = scrape_page(driver, url)\n",
    "            all_addresses.extend(addresses)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    # Save all extracted addresses to CSV\n",
    "    save_to_csv(all_addresses)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106b19c9-11a8-414e-9fc2-92570e41aa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL: https://deutsche.banklocationmaps.com/en/branches/deu?page=1&partner=hide\n",
      "Waiting for manual cookie consent. Please accept the cookies in the browser window...\n",
      "An error occurred: name 'time' is not defined\n",
      "Saving 0 addresses to deutsche_bank_branches.csv...\n",
      "Data saved successfully to deutsche_bank_branches.csv!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "\n",
    "# Initialize WebDriver\n",
    "def initialize_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # Comment out the following line for debugging purposes\n",
    "    # options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# Extract branch addresses from a single page\n",
    "def scrape_page(driver, url):\n",
    "    print(f\"Scraping URL: {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    print(\"Waiting for manual cookie consent. Please accept the cookies in the browser window...\")\n",
    "    time.sleep(60)  # Adjust the delay if needed (e.g., 15 seconds)\n",
    "\n",
    "    try:\n",
    "        # Wait for the address elements to load\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.media-body.pl-3 span.d-block.text-heading.font-size-sm.text-uppercase'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error waiting for page content: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Locate and extract branch addresses\n",
    "    branch_elements = driver.find_elements(By.CSS_SELECTOR, 'div.media-body.pl-3 span.d-block.text-heading.font-size-sm.text-uppercase')\n",
    "    addresses = []\n",
    "    for branch in branch_elements:\n",
    "        # Extract full address and handle <br> tags\n",
    "        address = branch.get_attribute(\"innerHTML\").replace(\"<br>\", \" \").strip()\n",
    "        print(f\"Extracted address: {address}\")\n",
    "        addresses.append(address)\n",
    "\n",
    "    print(f\"Found {len(addresses)} addresses on this page.\")\n",
    "    return addresses\n",
    "\n",
    "# Save extracted addresses to a CSV file\n",
    "def save_to_csv(data, filename=\"deutsche_bank_branches.csv\"):\n",
    "    print(f\"Saving {len(data)} addresses to {filename}...\")\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Address\"])  # Header row\n",
    "        for address in data:\n",
    "            writer.writerow([address])\n",
    "    print(f\"Data saved successfully to {filename}!\")\n",
    "\n",
    "# Main function to scrape all pages\n",
    "def main():\n",
    "    base_url = \"https://deutsche.banklocationmaps.com/en/branches/deu?page={}&partner=hide\"\n",
    "    total_pages = 39  # Number of pages to scrape\n",
    "    all_addresses = []\n",
    "\n",
    "    driver = initialize_driver()\n",
    "    try:\n",
    "        for page in range(1, total_pages + 1):\n",
    "            url = base_url.format(page)\n",
    "            addresses = scrape_page(driver, url)\n",
    "            all_addresses.extend(addresses)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    # Save all extracted addresses to CSV\n",
    "    save_to_csv(all_addresses)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30800487-e438-410c-aa9b-f3eae12e9b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
